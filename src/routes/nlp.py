from fastapi import FastAPI, APIRouter, status, Request
from fastapi.responses import JSONResponse
import logging 
from routes.schemes.nlp import PushRequest,SearchRequest
from models.ProjectModel import ProjectModel
from models.ChunkModel import ChunkModel
from controllers import NLPController
from models import ResponseSignal

logger = logging.error("uvicorn.error")

nlp_router = APIRouter(prefix="/api/v1/nlp",
                       tags=["nlp","ap1_v1"])

@nlp_router.post("/index/push/{project_id}")
async def index_project(request: Request, project_id: str, push_request: PushRequest):
    
    project_model = await ProjectModel.create_instance(
        request.app.db_client
    )
    
    chunk_model = await ChunkModel.create_instance(
        request.app.db_client
    )
    
    project = await project_model.get_project_or_create_one(project_id=project_id)
    
    if not project:
        return JSONResponse(
            content={
                "signal":ResponseSignal.PROJECT_NOT_FOUND_ERROR.value
                },
            status_code=status.HTTP_400_BAD_REQUEST
        )
    
    nlp_controller = NLPController(
        vectordb_client=request.app.vectordb_client,
        embedding_client=request.app.embedding_client,
        generation_client=request.app.generation_client,
        template_parser=request.app.template_parser
    )
    
    has_records = True
    page_no = 1 
    inserted_items_count = 0
    idx = 0
    
    
    while has_records:
        page_chunks = await chunk_model.get_project_chunks(project_id=project.id,page_no=page_no,page_size=5)
        if len(page_chunks):
            page_no+=1
        if len(page_chunks) == 0 or not page_chunks:
            has_records = False
            break
    
        chunk_ids = list(range(idx,idx+len(page_chunks)))
        idx+= len(page_chunks)
        
        is_inserted = nlp_controller.insert_into_vector_db(
            project=project,
            chunks=page_chunks,
            do_reset=push_request.do_reset,
            chunk_ids=chunk_ids
        )
        
        if not is_inserted:
            return JSONResponse(
                content={
                    "signal":ResponseSignal.CHUNKS_NOT_INSERTED_ERROR.value
                    },
                status_code=status.HTTP_400_BAD_REQUEST
            )
        inserted_items_count+=len(page_chunks)
        
    if is_inserted:
        return JSONResponse(
            content={
                "signal":ResponseSignal.CHUNKS_INSERTED_SUCCESS.value,
                "Inserted Chunks Count":inserted_items_count
                })


@nlp_router.get("/index/info/{project_id}")
async def get_project_index_info(request:Request,project_id:str):
    
    project_model = await ProjectModel.create_instance(
        request.app.db_client
    )
    
    
    project = await project_model.get_project_or_create_one(project_id=project_id)
    
    nlp_controller = NLPController(
        vectordb_client=request.app.vectordb_client,
        embedding_client=request.app.embedding_client,
        generation_client=request.app.generation_client,
        template_parser=request.app.template_parser
    )
    
    collection_info = nlp_controller.get_vector_db_collection_info(project=project)
    
    return JSONResponse(
            content={
                "signal":ResponseSignal.VECTORDB_COLLECTION_RETRIEVD.value,
                "Inserted Chunks Count": collection_info
                })
    
@nlp_router.post("/index/search/{project_id}")
async def get_project_index_info(request:Request,project_id:str,search_request:SearchRequest):
    
    project_model = await ProjectModel.create_instance(
        request.app.db_client
    )
    
    
    project = await project_model.get_project_or_create_one(project_id=project_id)
    
    nlp_controller = NLPController(
        vectordb_client=request.app.vectordb_client,
        embedding_client=request.app.embedding_client,
        generation_client=request.app.generation_client,
        template_parser = request.app.template_parser
    )
    
    results = nlp_controller.search_vector_db_collection(
        project=project,
        text=search_request.text,
        limit=search_request.limit
    )
    if not results:
        return JSONResponse(
            content={
                "signal":ResponseSignal.VECTORDB_SEARCH_ERROR.value
                },
            status_code=status.HTTP_400_BAD_REQUEST
        )
        
    return JSONResponse(
            content={
                "signal":ResponseSignal.VECTORDB_SEARCH_SUCCESS.value,
                "Results":[result.dict() for result in results]
                }
        )

@nlp_router.post("/index/answer/{project_id}")
async def answer_rag(request:Request,project_id:str,search_request:SearchRequest):
    
    project_model = await ProjectModel.create_instance(
        request.app.db_client
    )
    
    
    project = await project_model.get_project_or_create_one(project_id=project_id)
    
    nlp_controller = NLPController(
        vectordb_client=request.app.vectordb_client,
        embedding_client=request.app.embedding_client,
        generation_client=request.app.generation_client,
        template_parser = request.app.template_parser
    )
    
    answer,full_prompt,chat_histor = nlp_controller.answer_rag_question(
        project=project,query=search_request.text,limit=5
    )
    
    if not answer:
        return JSONResponse(
            status_code=status.HTTP_400_BAD_REQUEST,
            content={
                "singnal":ResponseSignal.RAG_ANSWER_ERROR.value
            }
        )
    
    return JSONResponse(
        content={
            "signal":ResponseSignal.RAG_ANSWER_SUCCESS.value,
            "Answer":answer
        }
    )